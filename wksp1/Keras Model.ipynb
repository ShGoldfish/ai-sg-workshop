{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you begin using Keras, import the required modules. If you are having problems with this step, make sure you have installed all dependencies found in requirements.txt and have selected the correct Python kernel (in the top menu, \"Kernel\"->\"Change kernel\"). If you are using virtualenv, your kernel will not show up unless you follow the instructions found [here](https://stackoverflow.com/questions/37891550/jupyter-notebook-running-kernel-in-different-env)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "First, we want to grab the dataset from the CSV file. Load it as a Pandas Dataframe so we can easily work with it in further steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>87930</td>\n",
       "      <td>B</td>\n",
       "      <td>12.47</td>\n",
       "      <td>18.60</td>\n",
       "      <td>81.09</td>\n",
       "      <td>481.9</td>\n",
       "      <td>0.09965</td>\n",
       "      <td>0.1058</td>\n",
       "      <td>0.08005</td>\n",
       "      <td>0.03821</td>\n",
       "      <td>...</td>\n",
       "      <td>24.64</td>\n",
       "      <td>96.05</td>\n",
       "      <td>677.9</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>0.2378</td>\n",
       "      <td>0.2671</td>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.3014</td>\n",
       "      <td>0.08750</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>859575</td>\n",
       "      <td>M</td>\n",
       "      <td>18.94</td>\n",
       "      <td>21.31</td>\n",
       "      <td>123.60</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>0.09009</td>\n",
       "      <td>0.1029</td>\n",
       "      <td>0.10800</td>\n",
       "      <td>0.07951</td>\n",
       "      <td>...</td>\n",
       "      <td>26.58</td>\n",
       "      <td>165.90</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>0.1193</td>\n",
       "      <td>0.2336</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.17890</td>\n",
       "      <td>0.2551</td>\n",
       "      <td>0.06589</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>8670</td>\n",
       "      <td>M</td>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.1223</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>...</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.1546</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>907915</td>\n",
       "      <td>B</td>\n",
       "      <td>12.40</td>\n",
       "      <td>17.68</td>\n",
       "      <td>81.47</td>\n",
       "      <td>467.8</td>\n",
       "      <td>0.10540</td>\n",
       "      <td>0.1316</td>\n",
       "      <td>0.07741</td>\n",
       "      <td>0.02799</td>\n",
       "      <td>...</td>\n",
       "      <td>22.91</td>\n",
       "      <td>89.61</td>\n",
       "      <td>515.8</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.2629</td>\n",
       "      <td>0.2403</td>\n",
       "      <td>0.07370</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>0.09359</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>921385</td>\n",
       "      <td>B</td>\n",
       "      <td>11.54</td>\n",
       "      <td>14.44</td>\n",
       "      <td>74.65</td>\n",
       "      <td>402.9</td>\n",
       "      <td>0.09984</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.06737</td>\n",
       "      <td>0.02594</td>\n",
       "      <td>...</td>\n",
       "      <td>19.68</td>\n",
       "      <td>78.78</td>\n",
       "      <td>457.8</td>\n",
       "      <td>0.1345</td>\n",
       "      <td>0.2118</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>0.06918</td>\n",
       "      <td>0.2329</td>\n",
       "      <td>0.08134</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "204   87930         B        12.47         18.60           81.09      481.9   \n",
       "70   859575         M        18.94         21.31          123.60     1130.0   \n",
       "131    8670         M        15.46         19.48          101.70      748.9   \n",
       "431  907915         B        12.40         17.68           81.47      467.8   \n",
       "540  921385         B        11.54         14.44           74.65      402.9   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "204          0.09965            0.1058         0.08005              0.03821   \n",
       "70           0.09009            0.1029         0.10800              0.07951   \n",
       "131          0.10920            0.1223         0.14660              0.08087   \n",
       "431          0.10540            0.1316         0.07741              0.02799   \n",
       "540          0.09984            0.1120         0.06737              0.02594   \n",
       "\n",
       "        ...       texture_worst  perimeter_worst  area_worst  \\\n",
       "204     ...               24.64            96.05       677.9   \n",
       "70      ...               26.58           165.90      1866.0   \n",
       "131     ...               26.00           124.90      1156.0   \n",
       "431     ...               22.91            89.61       515.8   \n",
       "540     ...               19.68            78.78       457.8   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "204            0.1426             0.2378           0.2671   \n",
       "70             0.1193             0.2336           0.2687   \n",
       "131            0.1546             0.2394           0.3791   \n",
       "431            0.1450             0.2629           0.2403   \n",
       "540            0.1345             0.2118           0.1797   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
       "204               0.10150          0.3014                  0.08750   \n",
       "70                0.17890          0.2551                  0.06589   \n",
       "131               0.15140          0.2837                  0.08019   \n",
       "431               0.07370          0.2556                  0.09359   \n",
       "540               0.06918          0.2329                  0.08134   \n",
       "\n",
       "     Unnamed: 32  \n",
       "204          NaN  \n",
       "70           NaN  \n",
       "131          NaN  \n",
       "431          NaN  \n",
       "540          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dataset(path):\n",
    "    dataset = pd.read_csv(path)\n",
    "    np.random.seed(42)\n",
    "    dataset = dataset.reindex(np.random.permutation(dataset.index))\n",
    "    return dataset\n",
    "\n",
    "dataset = get_dataset('data/dataset.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll write functions to get the data and the labels (i.e. the x and the y). We want to make sure these return NumPy arrays so they can be passed into Keras models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) (569,)\n"
     ]
    }
   ],
   "source": [
    "def get_data(dataset):\n",
    "    data = np.array(dataset.as_matrix()[:, 2:-1], dtype=np.float64)\n",
    "    return data\n",
    "\n",
    "def get_labels(dataset):\n",
    "    diagnoses = dataset['diagnosis'].map({'M':1, 'B':0})\n",
    "    return np.array(diagnoses.as_matrix(), dtype=np.uint8)\n",
    "\n",
    "data, labels = get_data(dataset), get_labels(dataset)\n",
    "print(data.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll split the data and labels into train, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(data, labels, split):\n",
    "    train_ratio, val_ratio, test_ratio = split\n",
    "    num_examples = labels.shape[0]\n",
    "    train_bound, val_bound = int(train_ratio*num_examples), int(train_ratio*num_examples) + int(val_ratio*num_examples)\n",
    "    \n",
    "    train = {'data': data[:train_bound], 'labels': labels[:train_bound]}\n",
    "    val = {'data': data[train_bound:val_bound], 'labels': labels[train_bound:val_bound]}\n",
    "    test = {'data': data[val_bound:], 'labels': labels[val_bound:]}\n",
    "    \n",
    "    return train, val, test\n",
    "    \n",
    "train, val, test = split_data(data, labels, (.7, .2, .1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to scale our data so that each feature has mean 0 and variance 1. This is useful because it improves the stability of training our neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train['data'])\n",
    "train['data'] = scaler.transform(train['data'])\n",
    "val['data'] = scaler.transform(val['data'])\n",
    "test['data'] = scaler.transform(test['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture and Training\n",
    "\n",
    "Let's define our model's architecture first. We want a 4-layer Fully-Connected Network that can be used for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -4.51093897e-01  -1.74980482e-01  -4.27986424e-01  -4.82623057e-01\n",
      "    2.71028366e-01   4.02532786e-02  -9.62593209e-02  -2.53758788e-01\n",
      "    3.92284204e-01   1.11635089e-01  -1.87708345e-02  -3.43117512e-01\n",
      "   -1.88953747e-01  -2.47729895e-01  -1.67306731e-02  -3.61543866e-01\n",
      "   -1.52759925e-01  -1.97128787e-01  -3.43368170e-01  -8.07385172e-02\n",
      "   -2.53564185e-01  -1.81859419e-01  -3.17894877e-01  -3.48243160e-01\n",
      "    4.86947699e-01  -9.81702448e-02  -9.74849555e-03  -1.67030262e-01\n",
      "    1.68017627e-01   1.95903816e-01]\n",
      " [  1.37951098e+00   4.59877055e-01   1.31564541e+00   1.38662702e+00\n",
      "   -4.15552286e-01  -1.37439950e-02   2.48163253e-01   7.91728780e-01\n",
      "   -8.07874597e-01  -1.15369273e+00   1.58622948e+00  -7.73899212e-01\n",
      "    1.53011497e+00   1.57208349e+00  -8.83138857e-01  -5.09192535e-01\n",
      "   -2.85011489e-01   3.61097340e-01  -8.13550564e-01  -7.73305407e-01\n",
      "    1.76755742e+00   1.39101734e-01   1.72973556e+00   1.73861640e+00\n",
      "   -5.47610608e-01  -1.25117612e-01  -2.13205357e-03   9.99528325e-01\n",
      "   -5.59541535e-01  -9.86890243e-01]\n",
      " [  3.94888883e-01   3.11725187e-02   4.17373538e-01   2.87458367e-01\n",
      "    9.56890837e-01   3.47479146e-01   7.23823765e-01   8.26156457e-01\n",
      "    4.13278236e-01  -6.88906745e-01   3.00839618e-01  -7.94171292e-01\n",
      "    1.54399891e-01   2.50947677e-01  -2.62943919e-01  -6.04964644e-01\n",
      "   -1.18472483e-01  -1.03252922e-01  -8.00489942e-01  -4.93417411e-01\n",
      "    6.23140736e-01   4.31442756e-02   5.27833655e-01   4.91524164e-01\n",
      "    1.01976743e+00  -8.79045812e-02   5.23402443e-01   5.85053375e-01\n",
      "   -1.10120541e-01  -2.04199126e-01]\n",
      " [ -4.70899514e-01  -3.90504074e-01  -4.12399972e-01  -5.23290278e-01\n",
      "    6.83982210e-01   5.20642816e-01  -1.28791542e-01  -5.12472661e-01\n",
      "   -6.60239433e-03   1.12306489e+00  -9.15478420e-01   3.83881219e-01\n",
      "   -3.57467342e-01  -6.58959014e-01   1.03545974e+00   4.27435891e-01\n",
      "    5.08497895e-01   2.07973286e-02   1.37500189e-01   8.06612811e-01\n",
      "   -6.80676840e-01  -4.68077355e-01  -5.06681419e-01  -6.32966614e-01\n",
      "    5.93511645e-01   6.28723536e-02  -1.37323899e-01  -5.86026757e-01\n",
      "   -5.51684525e-01   5.29231711e-01]\n",
      " [ -7.14225665e-01  -1.14952194e+00  -6.92135777e-01  -7.10474864e-01\n",
      "    2.84673797e-01   1.55695726e-01  -2.52512567e-01  -5.64367322e-01\n",
      "    1.78906424e-02   6.79090219e-01  -4.99821349e-01   9.22139894e-01\n",
      "   -6.88743213e-01  -5.08691577e-01   1.77789800e+00   8.93184780e-01\n",
      "    7.20345308e-01   5.68965327e-01  -2.74503071e-01   6.25767749e-01\n",
      "   -8.07380115e-01  -1.00246113e+00  -8.24159409e-01  -7.34841754e-01\n",
      "    1.27294382e-01  -2.64987279e-01  -4.25796639e-01  -6.54151367e-01\n",
      "   -9.08392796e-01  -1.41255435e-01]\n",
      " [  1.84918704e+00   2.33868054e+00   1.99242558e+00   1.77599403e+00\n",
      "    1.57452615e+00   3.22795440e+00   3.24753550e+00   2.62677463e+00\n",
      "    2.04381468e+00   1.00374670e+00   1.32956022e+00   6.19806288e-01\n",
      "    1.69460264e+00   1.30005238e+00  -1.65563645e-01   2.05955225e+00\n",
      "    1.19914495e+00   8.53945632e-01   3.00164300e-01   8.72641434e-01\n",
      "    1.94739432e+00   2.26340132e+00   2.27792008e+00   1.65957535e+00\n",
      "    1.48154453e+00   3.94585963e+00   3.18725303e+00   2.29721171e+00\n",
      "    1.85413206e+00   2.19368184e+00]\n",
      " [  2.24812875e+00   5.98093272e-01   2.28364614e+00   2.40186545e+00\n",
      "    7.48618463e-01   1.70858284e+00   1.93392383e+00   2.57867714e+00\n",
      "    3.88846739e-02  -2.11633970e-01   2.48211965e+00  -9.44464299e-01\n",
      "    2.72351329e+00   2.51713560e+00  -1.04405803e+00   1.57221726e-01\n",
      "    1.15110720e-01   5.30409168e-01  -6.56823099e-01  -3.70512374e-03\n",
      "    2.33976576e+00   1.00554969e-02   2.58279276e+00   2.37270133e+00\n",
      "   -9.91540031e-02   8.68726950e-01   9.82769100e-01   1.96864612e+00\n",
      "   -2.60975140e-01   9.95726013e-02]\n",
      " [  9.91886766e-01  -1.00662043e+00   9.62899375e-01   8.82180426e-01\n",
      "    1.86283055e-01   2.24588799e-01   1.34177249e-01   7.92235069e-01\n",
      "   -2.58530772e-01  -1.99147183e-01   8.15812980e-01  -7.30209384e-01\n",
      "    1.05218051e+00   6.04892524e-01  -4.74625154e-01   2.78077006e-01\n",
      "    6.33734179e-02   3.34275664e-01  -1.73580083e-01  -2.35137106e-02\n",
      "    7.76410828e-01  -1.02893215e+00   8.20980460e-01   6.16233388e-01\n",
      "   -2.72320415e-01   1.80285882e-01  -9.63855231e-02   4.97636840e-01\n",
      "   -2.37404109e-01  -2.58932770e-01]\n",
      " [ -2.04938373e-01  -8.16865963e-01  -2.06494731e-01  -3.72735033e-01\n",
      "    8.56345553e-01   9.28415331e-01   3.57836272e-01   5.47697299e-01\n",
      "    4.51767293e-01   8.45580722e-01  -4.68759463e-01  -3.92050119e-01\n",
      "   -7.42230463e-01  -7.27312711e-01  -7.16365724e-02   5.87056073e-01\n",
      "    2.38790423e-01   3.82889951e-01   7.45717369e-02   2.92323203e-01\n",
      "   -1.39122517e-01  -4.21753065e-01  -3.00012922e-01  -4.58900640e-01\n",
      "    9.75365784e-01   1.45002015e+00   1.03132392e+00   8.77446613e-01\n",
      "    9.74146892e-01   9.67648203e-01]\n",
      " [ -4.64934370e-02  -6.38824735e-01  -1.04772620e-01  -1.43729546e-01\n",
      "   -1.98190417e+00  -9.39331744e-01  -8.08641037e-01  -8.82063907e-01\n",
      "    3.95616172e-04  -1.04963617e+00  -1.00212473e+00  -1.16064157e+00\n",
      "   -8.24474300e-01  -6.97702000e-01  -1.27542251e+00  -7.01306825e-01\n",
      "   -6.76439382e-01  -1.12549404e+00  -8.96663614e-01  -6.27675611e-01\n",
      "   -2.18822965e-01  -6.51720077e-01  -1.66924272e-01  -2.76227974e-01\n",
      "   -1.67807647e+00  -3.36846925e-01  -6.22396047e-01  -7.59051209e-01\n",
      "   -3.58402069e-01  -3.79894125e-01]] [0 1 1 0 0 1 1 1 0 0]\n",
      "0.994974874372\n",
      "[0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 1\n",
      " 0 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 0 0 1 0 0 1\n",
      " 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 1\n",
      " 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1\n",
      " 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 1 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 1 0 1 0\n",
      " 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 1 0 1 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1\n",
      " 0 1 1 0 0 1 1 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1\n",
      " 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1]\n",
      "0.964601769912\n",
      "[0 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 0 1 0 1\n",
      " 1 0 1 1 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0 0 1\n",
      " 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Karan/tf3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "print(train['data'][:10], train[\"labels\"][:10])\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# baseline_model = SVC(kernel='poly', degree=2)\n",
    "# baseline_model.fit(train['data'], train['labels'])\n",
    "# print(baseline_model.score(val['data'], val['labels']))\n",
    "\n",
    "baseline_mlp = MLPClassifier()\n",
    "baseline_mlp.fit(train['data'], train['labels'])\n",
    "print(baseline_mlp.score(train['data'], train['labels']))\n",
    "print(baseline_mlp.predict(train['data']))\n",
    "print(baseline_mlp.score(val['data'], val['labels']))\n",
    "print(baseline_mlp.predict(val['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_109 (Dense)            (None, 16)                496       \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 673\n",
      "Trainable params: 673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, activation='relu', input_dim=30))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    sgd = SGD(lr=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train our model! We want to not only train the model with many epochs, but also print the validation set accuracy at every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "512/512 [==============================] - 0s - loss: 7.4927e-04 - acc: 1.0000     \n",
      "Epoch 2/25\n",
      "512/512 [==============================] - 0s - loss: 7.0824e-04 - acc: 1.0000     \n",
      "Epoch 3/25\n",
      "512/512 [==============================] - 0s - loss: 6.8463e-04 - acc: 1.0000     \n",
      "Epoch 4/25\n",
      "512/512 [==============================] - 0s - loss: 6.5316e-04 - acc: 1.0000     \n",
      "Epoch 5/25\n",
      "512/512 [==============================] - 0s - loss: 6.3599e-04 - acc: 1.0000     \n",
      "Epoch 6/25\n",
      "512/512 [==============================] - 0s - loss: 6.4775e-04 - acc: 1.0000     \n",
      "Epoch 7/25\n",
      "512/512 [==============================] - 0s - loss: 5.8751e-04 - acc: 1.0000     \n",
      "Epoch 8/25\n",
      "512/512 [==============================] - 0s - loss: 6.1608e-04 - acc: 1.0000     \n",
      "Epoch 9/25\n",
      "512/512 [==============================] - 0s - loss: 5.6789e-04 - acc: 1.0000     \n",
      "Epoch 10/25\n",
      "512/512 [==============================] - 0s - loss: 5.5468e-04 - acc: 1.0000     \n",
      "Epoch 11/25\n",
      "512/512 [==============================] - 0s - loss: 5.3320e-04 - acc: 1.0000     \n",
      "Epoch 12/25\n",
      "512/512 [==============================] - 0s - loss: 5.0301e-04 - acc: 1.0000     \n",
      "Epoch 13/25\n",
      "512/512 [==============================] - 0s - loss: 4.9857e-04 - acc: 1.0000     \n",
      "Epoch 14/25\n",
      "512/512 [==============================] - 0s - loss: 4.8642e-04 - acc: 1.0000     \n",
      "Epoch 15/25\n",
      "512/512 [==============================] - 0s - loss: 4.6146e-04 - acc: 1.0000     \n",
      "Epoch 16/25\n",
      "512/512 [==============================] - 0s - loss: 4.3956e-04 - acc: 1.0000     \n",
      "Epoch 17/25\n",
      "512/512 [==============================] - 0s - loss: 4.3564e-04 - acc: 1.0000     \n",
      "Epoch 18/25\n",
      "512/512 [==============================] - 0s - loss: 4.3488e-04 - acc: 1.0000     \n",
      "Epoch 19/25\n",
      "512/512 [==============================] - 0s - loss: 4.0948e-04 - acc: 1.0000     \n",
      "Epoch 20/25\n",
      "512/512 [==============================] - 0s - loss: 3.9720e-04 - acc: 1.0000     \n",
      "Epoch 21/25\n",
      "512/512 [==============================] - 0s - loss: 3.8000e-04 - acc: 1.0000     \n",
      "Epoch 22/25\n",
      "512/512 [==============================] - 0s - loss: 3.7253e-04 - acc: 1.0000     \n",
      "Epoch 23/25\n",
      "512/512 [==============================] - 0s - loss: 3.6019e-04 - acc: 1.0000     \n",
      "Epoch 24/25\n",
      "512/512 [==============================] - 0s - loss: 3.4967e-04 - acc: 1.0000     \n",
      "Epoch 25/25\n",
      "512/512 [==============================] - 0s - loss: 3.3338e-04 - acc: 1.0000     \n",
      "[1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "Validation accuracy: 0.93\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train, val, num_epochs):\n",
    "    model.fit(train['data'], train['labels'], epochs=num_epochs, verbose=1, batch_size=16)\n",
    "    results = model.predict(val['data'])\n",
    "    print([0 if x < .5 else 1 for x in results])\n",
    "    score = model.evaluate(val['data'], val['labels'], batch_size=16, verbose=0)\n",
    "    print(\"Validation accuracy: %.2f\\n\" % (score[1]))\n",
    "        \n",
    "train_model(model, train, val, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Try playing around with hyperparameters like the learning rate, size of the hidden layers, number of epochs, etc. until you get a model that you are satisfied with! Use validation accuracy to compare performance across different model configurations. Once you're done configuring, try testing on a completely unseen dataset to get a good idea of how your model will perform for unseen data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s\n",
      "Test accuracy: 0.36\n"
     ]
    }
   ],
   "source": [
    "test_score = model.evaluate(test['data'], test['labels'], batch_size=128)\n",
    "print(\"Test accuracy: %.2f\" % (test_score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf3.5",
   "language": "python",
   "name": "tf3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
